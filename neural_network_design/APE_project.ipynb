{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOCO6oh7gGmCejdKjfphYG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Load dataset"],"metadata":{"id":"bvU5-v0Xc_lC"}},{"cell_type":"code","source":["\n","from google.colab import files\n","import zipfile\n","import io\n","import os\n","import glob\n","\n","# Change to true to opload new data\n","if not os.path.exists('/content/data.zip'):\n","    uploaded = files.upload()\n","\n","    for fn in uploaded.keys():\n","        print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n","\n","    if 'data.zip' in uploaded:\n","        zf = zipfile.ZipFile(io.BytesIO(uploaded['data.zip']), \"r\")\n","        zf.extractall()\n","\n","training_folder = \"/content/training_data\"\n","testing_folder = \"/content/testing_data\""],"metadata":{"id":"mbBdSC4Cbqv0","executionInfo":{"status":"ok","timestamp":1685276030276,"user_tz":-120,"elapsed":16152,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"colab":{"base_uri":"https://localhost:8080/","height":92},"outputId":"dbacf298-9dc2-4425-a938-25e4078b060c"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-02701575-d6fc-4f09-8532-be735ca7ff22\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-02701575-d6fc-4f09-8532-be735ca7ff22\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving data.zip to data.zip\n","User uploaded file \"data.zip\" with length 773029 bytes\n"]}]},{"cell_type":"markdown","source":["Load library"],"metadata":{"id":"L3SiqgrVc-dE"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRKJTJ4Oa8fX","executionInfo":{"status":"ok","timestamp":1685276035326,"user_tz":-120,"elapsed":5053,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"7650a09b-5f94-4745-fdff-cb27e77274f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.12.0\n"]}],"source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)\n","\n","import numpy as np\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","source":["Create dataset"],"metadata":{"id":"BO91XUUec2xh"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","category_number = {\"still\" : 0, \"circle\" : 1, \"eight\" : 2, \"line\" : 3}\n","\n","def load_to_numpy(path: str, category: dict):\n","    files = glob.glob(path + \"/**/*.txt\", recursive=True)\n","\n","    final_x_data = []\n","    final_y_data = []\n","\n","    for file in files:\n","        print(file)\n","        y_val = category_number[os.path.basename(os.path.dirname(file))]\n","\n","        x_data = np.genfromtxt(file, delimiter=\",\")\n","        x_data = x_data[:, :-1] / (2**12)\n","\n","        y_data = [y_val]\n","        y_data = tf.keras.utils.to_categorical(y_data, num_classes=4)\n","\n","        final_x_data.append(x_data)\n","        final_y_data.append(y_data)\n","\n","    return final_x_data, final_y_data\n","\n","def train_generator(list_x_data, list_y_data):\n","    while True:\n","        sequence_length = np.random.randint(50, 1000)\n","\n","        final_x_train = None\n","        final_y_train = None\n","\n","        for x_data, y_data in zip(list_x_data, list_y_data):\n","\n","            size_first_axis = x_data.shape[0] // sequence_length\n","            cropped_x_data = x_data[:size_first_axis * sequence_length, :]\n","\n","            # Reshape the cropped array\n","            x_train = cropped_x_data.reshape((size_first_axis, sequence_length, x_data.shape[1]))\n","            y_train = np.tile(y_data, (size_first_axis, 1))\n","\n","            if final_x_train is None:\n","                final_x_train = x_train\n","            else:\n","                final_x_train = np.vstack((final_x_train, x_train))\n","\n","            if final_y_train is None:\n","                final_y_train = y_train\n","            else:\n","                final_y_train = np.vstack((final_y_train, y_train))\n","\n","        yield final_x_train, final_y_train\n","\n","def test_generator(list_x_data, list_y_data):\n","    for x_data, y_data in zip(list_x_data, list_y_data):\n","        yield x_data.reshape(1, x_data.shape[0], x_data.shape[1]), y_data\n","\n","list_x_train, list_y_train = load_to_numpy(training_folder, category_number)\n","\n","print(list_x_train[0][0])\n","\n","list_x_test, list_y_test = load_to_numpy(testing_folder, category_number)\n","\n","gen = train_generator(list_x_train, list_y_train)\n","x, y = next(gen)\n","print(f\"{x.shape = } and {y.shape = }\")\n","\n","\n","gen = test_generator(list_x_test, list_y_test)\n","\n","for x, y in gen:\n","    print(f\"{x.shape = } and {y.shape = }\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poK4O3Cxc5Su","executionInfo":{"status":"ok","timestamp":1685276035606,"user_tz":-120,"elapsed":283,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"7e6be0e2-0c0e-440f-d809-3c0f41643e78"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_data/eight/eight_pattern_0.txt\n","/content/training_data/eight/eight_pattern_1.txt\n","/content/training_data/eight/eight_pattern_2.txt\n","/content/training_data/line/line_3.txt\n","/content/training_data/line/line_2.txt\n","/content/training_data/line/line_0.txt\n","/content/training_data/line/line_1.txt\n","/content/training_data/circle/circle_2.txt\n","/content/training_data/circle/circle_0.txt\n","/content/training_data/circle/circle_1.txt\n","/content/training_data/still/still_1.txt\n","/content/training_data/still/still_0.txt\n","[-0.05126953  0.18579102  0.46166992  0.66040039  0.4362793   0.30078125]\n","/content/testing_data/eight/eight2.txt\n","/content/testing_data/eight/eight1.txt\n","/content/testing_data/eight/eight0.txt\n","/content/testing_data/eight/eight3.txt\n","/content/testing_data/line/line0.txt\n","/content/testing_data/line/line1.txt\n","/content/testing_data/line/line3.txt\n","/content/testing_data/line/line2.txt\n","/content/testing_data/circle/circle1.txt\n","/content/testing_data/circle/circle3.txt\n","/content/testing_data/circle/circle0.txt\n","/content/testing_data/circle/circle2.txt\n","/content/testing_data/still/still3.txt\n","/content/testing_data/still/still0.txt\n","/content/testing_data/still/still2.txt\n","/content/testing_data/still/still1.txt\n","x.shape = (56, 875, 6) and y.shape = (56, 4)\n","x.shape = (1, 585, 6) and y.shape = (1, 4)\n","x.shape = (1, 571, 6) and y.shape = (1, 4)\n","x.shape = (1, 412, 6) and y.shape = (1, 4)\n","x.shape = (1, 534, 6) and y.shape = (1, 4)\n","x.shape = (1, 356, 6) and y.shape = (1, 4)\n","x.shape = (1, 224, 6) and y.shape = (1, 4)\n","x.shape = (1, 356, 6) and y.shape = (1, 4)\n","x.shape = (1, 428, 6) and y.shape = (1, 4)\n","x.shape = (1, 478, 6) and y.shape = (1, 4)\n","x.shape = (1, 465, 6) and y.shape = (1, 4)\n","x.shape = (1, 361, 6) and y.shape = (1, 4)\n","x.shape = (1, 585, 6) and y.shape = (1, 4)\n","x.shape = (1, 215, 6) and y.shape = (1, 4)\n","x.shape = (1, 208, 6) and y.shape = (1, 4)\n","x.shape = (1, 612, 6) and y.shape = (1, 4)\n","x.shape = (1, 329, 6) and y.shape = (1, 4)\n"]}]},{"cell_type":"markdown","source":["Create network"],"metadata":{"id":"uFDbUrPidrfh"}},{"cell_type":"code","source":["\n","def create_model():\n","    # Hyperparameters\n","    drop = 0.3\n","    rec_drop = 0.3\n","\n","    model = tf.keras.Sequential(name=\"LSTM-Model\")\n","\n","    model.add(tf.keras.Input(shape=(None, 6)))\n","    model.add(layers.LSTM(32, activation=\"tanh\", recurrent_activation='hard_sigmoid', dropout=drop, recurrent_dropout=rec_drop, return_sequences=True))\n","    model.add(layers.LSTM(16, activation=\"tanh\", recurrent_activation='hard_sigmoid', dropout=drop, recurrent_dropout=rec_drop))\n","    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n","\n","    return model\n","\n","model = create_model()\n","\n","print(model.summary())\n","\n","# Restore the weights\n","#model.load_weights('/content/my_checkpoint')\n","\n","\n","model.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","    metrics=[\"accuracy\"],\n",")\n"],"metadata":{"id":"R17aMoAVdwlH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685276036221,"user_tz":-120,"elapsed":617,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"d03408a7-2989-4bb7-c542-5c029cb1cd28"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"LSTM-Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, None, 32)          4992      \n","                                                                 \n"," lstm_1 (LSTM)               (None, 16)                3136      \n","                                                                 \n"," dense (Dense)               (None, 4)                 68        \n","                                                                 \n","=================================================================\n","Total params: 8,196\n","Trainable params: 8,196\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","source":["Train model"],"metadata":{"id":"RTlGCjb820uC"}},{"cell_type":"code","source":["model.fit(train_generator(list_x_train, list_y_train), steps_per_epoch=10, epochs=20, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUDOXczrdqKb","executionInfo":{"status":"ok","timestamp":1685278268548,"user_tz":-120,"elapsed":382442,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"fc30b03a-b653-4e0c-f288-205d8cba8c76"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","10/10 - 15s - loss: 0.8505 - accuracy: 0.6795 - 15s/epoch - 2s/step\n","Epoch 2/20\n","10/10 - 14s - loss: 0.8029 - accuracy: 0.7193 - 14s/epoch - 1s/step\n","Epoch 3/20\n","10/10 - 19s - loss: 0.8534 - accuracy: 0.7075 - 19s/epoch - 2s/step\n","Epoch 4/20\n","10/10 - 17s - loss: 0.6396 - accuracy: 0.7822 - 17s/epoch - 2s/step\n","Epoch 5/20\n","10/10 - 18s - loss: 0.8629 - accuracy: 0.5984 - 18s/epoch - 2s/step\n","Epoch 6/20\n","10/10 - 24s - loss: 0.9870 - accuracy: 0.5313 - 24s/epoch - 2s/step\n","Epoch 7/20\n","10/10 - 18s - loss: 0.8120 - accuracy: 0.6873 - 18s/epoch - 2s/step\n","Epoch 8/20\n","10/10 - 18s - loss: 0.7406 - accuracy: 0.7462 - 18s/epoch - 2s/step\n","Epoch 9/20\n","10/10 - 15s - loss: 1.1327 - accuracy: 0.6182 - 15s/epoch - 1s/step\n","Epoch 10/20\n","10/10 - 17s - loss: 0.7442 - accuracy: 0.7539 - 17s/epoch - 2s/step\n","Epoch 11/20\n","10/10 - 17s - loss: 0.7042 - accuracy: 0.7677 - 17s/epoch - 2s/step\n","Epoch 12/20\n","10/10 - 17s - loss: 0.8330 - accuracy: 0.7030 - 17s/epoch - 2s/step\n","Epoch 13/20\n","10/10 - 16s - loss: 0.7025 - accuracy: 0.7709 - 16s/epoch - 2s/step\n","Epoch 14/20\n","10/10 - 21s - loss: 0.8093 - accuracy: 0.7040 - 21s/epoch - 2s/step\n","Epoch 15/20\n","10/10 - 16s - loss: 0.6859 - accuracy: 0.7659 - 16s/epoch - 2s/step\n","Epoch 16/20\n","10/10 - 17s - loss: 0.6851 - accuracy: 0.7670 - 17s/epoch - 2s/step\n","Epoch 17/20\n","10/10 - 24s - loss: 0.5431 - accuracy: 0.8415 - 24s/epoch - 2s/step\n","Epoch 18/20\n","10/10 - 21s - loss: 0.9165 - accuracy: 0.6928 - 21s/epoch - 2s/step\n","Epoch 19/20\n","10/10 - 19s - loss: 0.7787 - accuracy: 0.7206 - 19s/epoch - 2s/step\n","Epoch 20/20\n","10/10 - 22s - loss: 0.6512 - accuracy: 0.7586 - 22s/epoch - 2s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f29d88b2800>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["model.evaluate(test_generator(list_x_test, list_y_test), verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fh0D0uMX-J83","executionInfo":{"status":"ok","timestamp":1685278273599,"user_tz":-120,"elapsed":5056,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"89de4a0a-c3c3-41fd-c015-016cd8701435"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 - 3s - loss: 0.5347 - accuracy: 0.8125 - 3s/epoch - 196ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.534674346446991, 0.8125]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Save weights to c-style txt files"],"metadata":{"id":"USzaDVHBdhMz"}},{"cell_type":"code","source":["def write_values(file, weights, last=True, top=True):\n","    file.write('{')\n","    for i in range(weights.shape[0]):\n","        if 1 == len(weights.shape):\n","            file.write(str(weights[i]))\n","            if i != weights.shape[0]-1:\n","                file.write(', ')\n","        else:\n","            write_values(file, weights[i], (i==weights.shape[0]-1), top=False)\n","    file.write('}')\n","    if top:\n","        file.write(';')\n","\n","    if last:\n","        file.write('\\n')\n","    else:\n","        file.write(', \\n')\n","\n","\n","#for w in range(1, len(model.layers)):\n","for layer in range(0, 2):\n","    \n","    weight_filename = \"/content/layer_\" + str(layer) + \"_weights.txt\" \n","\n","    with open(weight_filename, 'w') as file: # clear file\n","    \n","        file.write(f\"#define layer_{layer}_input_size {model.layers[layer].weights[0].numpy().shape[0]} \\n\")\n","        file.write(f\"#define layer_{layer}_kernel_size {model.layers[layer].weights[0].numpy().shape[1]} \\n\")\n","        file.write(f\"const data_t layer_{layer}_kernel_weights[layer_{layer}_input_size][layer_{layer}_kernel_size] = \")\n","        write_values(file, model.layers[layer].weights[0].numpy())\n","\n","        file.write(f\"#define layer_{layer}_recurrent_kernel_size_0 {model.layers[layer].weights[1].numpy().shape[0]} \\n\")\n","        file.write(f\"#define layer_{layer}_recurrent_kernel_size_1 {model.layers[layer].weights[1].numpy().shape[1]} \\n\")\n","        file.write(f\"const data_t layer_{layer}_recurrent_kernel_weights[layer_{layer}_recurrent_kernel_size_0][layer_{layer}_recurrent_kernel_size_1] = \")\n","        write_values(file, model.layers[layer].weights[1].numpy())\n","\n","        file.write(f\"#define layer_{layer}_bias_size {model.layers[layer].weights[2].numpy().shape[0]} \\n\")\n","        file.write(f\"const data_t layer_{layer}_bias_weights[layer_{layer}_bias_size] = \")\n","        write_values(file, model.layers[layer].weights[2].numpy())\n","\n","\n","layer = 2\n","weight_filename = \"/content/layer_\" + str(layer) + \"_weights.txt\"\n","\n","with open(weight_filename, 'w') as file: # clear file\n","\n","    file.write(f\"#define layer_{layer}_input_size {model.layers[layer].weights[0].numpy().shape[0]} \\n\")\n","    file.write(f\"#define layer_{layer}_kernel_size {model.layers[layer].weights[0].numpy().shape[1]} \\n\")\n","    file.write(f\"const data_t layer_{layer}_weights[layer_{layer}_input_size][layer_{layer}_kernel_size] = \")\n","    write_values(file, model.layers[layer].weights[0].numpy())\n","\n","    file.write(f\"#define layer_{layer}_bias_size {model.layers[layer].weights[1].numpy().shape[0]} \\n\")\n","    file.write(f\"const data_t layer_{layer}_bias_weights[layer_{layer}_bias_size] = \")\n","    write_values(file, model.layers[layer].weights[1].numpy())"],"metadata":{"id":"W0jGhymkLpws","executionInfo":{"status":"ok","timestamp":1685278273600,"user_tz":-120,"elapsed":10,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Zip weights"],"metadata":{"id":"YrKn8w22uv-n"}},{"cell_type":"code","source":["# Directory path where the files are located\n","directory = '/content'\n","\n","# Find all files ending with \"weights.txt\"\n","file_paths = glob.glob(directory + '/*weights.txt')\n","\n","# Zip the files\n","with zipfile.ZipFile('/content/weights.zip', 'w') as zip_file:\n","    for file_path in file_paths:\n","        zip_file.write(file_path, arcname=file_path.split('/')[-1])"],"metadata":{"id":"EUzksHY8uxui","executionInfo":{"status":"ok","timestamp":1685278273601,"user_tz":-120,"elapsed":10,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model.save_weights('/content/my_checkpoint')"],"metadata":{"id":"qWXgoli03JwK","executionInfo":{"status":"ok","timestamp":1685278273602,"user_tz":-120,"elapsed":9,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["For debugging layers"],"metadata":{"id":"ccXlXLsIM9hl"}},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","\n","test_model = create_model()\n","\n","print(model.summary())\n","# Restore the weights\n","test_model.load_weights('/content/my_checkpoint')\n","\n","XX = test_model.input \n","YY = test_model.layers[0].output\n","new_model = Model(XX, YY)\n","\n","for i in range(10):\n","    x = np.full((1, i + 1, 6), 5.0/4096)\n","    y = test_model(x)\n","    print(y.numpy())\n","    print(np.argmax(y.numpy()))\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFNpRRJU3Yl3","executionInfo":{"status":"ok","timestamp":1685278539701,"user_tz":-120,"elapsed":2016,"user":{"displayName":"Rasmus Faurskov","userId":"10252724822891172449"}},"outputId":"0eedc8cc-3c11-4c7a-b9cd-b6452cac13b3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"LSTM-Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, None, 32)          4992      \n","                                                                 \n"," lstm_1 (LSTM)               (None, 16)                3136      \n","                                                                 \n"," dense (Dense)               (None, 4)                 68        \n","                                                                 \n","=================================================================\n","Total params: 8,196\n","Trainable params: 8,196\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"]},{"output_type":"stream","name":"stdout","text":["None\n","[[0.346277   0.23488112 0.24178158 0.17706029]]\n","0\n","[[0.33470246 0.23595706 0.25155118 0.1777893 ]]\n","0\n","[[0.31555048 0.23938486 0.26574817 0.17931646]]\n","0\n","[[0.29011178 0.24390319 0.28416643 0.18181865]]\n","0\n","[[0.26049334 0.24788085 0.30615917 0.18546669]]\n","2\n","[[0.22941634 0.24946567 0.33055726 0.19056082]]\n","2\n","[[0.19968942 0.24693656 0.3557511  0.19762294]]\n","2\n","[[0.17353098 0.23915485 0.37996903 0.20734519]]\n","2\n","[[0.15210976 0.22591941 0.401646   0.2203248 ]]\n","2\n","[[0.13554733 0.20807372 0.4197126  0.23666638]]\n","2\n"]}]}]}